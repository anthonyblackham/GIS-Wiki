{
    "docs": [
        {
            "location": "/",
            "text": "Welcome to the GIS-Blog wiki!\n\n\nI am going to use this wiki as my template for content, in the future I will create a prettier blog with github pages.",
            "title": "Home"
        },
        {
            "location": "/ArcMap-EMF-files/",
            "text": "If you want logos and icons to be scalable with your maps then you'll want something vector based. One way to do this is with an EMF file.\n\n\nAdding an EMF file to arcmap:\n\n\nCustomize>Style Manager>\nC:\\Users\\USERNAME\\AppData\\Roaming\\ESRI\\Desktop10.x\\Arcmap\\USERNAME.style\nNorth arrows> New>symbol>edit symbol>type: Picture Marker Symbol\nSize: 80?",
            "title": "Arcmap EMF Files"
        },
        {
            "location": "/Converting-Degrees-to-Decimals/",
            "text": "Latitude and Longitude can be expressed in terms of Degrees, Minutes, and Seconds \n45\u00b0 30' 47.39\"\n or in decimal degrees \n45.513163\n\n\nIf you want to convert to Degrees, Minutes, Seconds:\n\n\ndd = d + m/60 + s/3600\n\n\nSo for the example above \n45\u00b0 30' 47.39\"\n:\n\n\n45 + 30/60 + 47.39/3600 = 45.513163\n\n\nIf you want to convert decimal degrees to degrees minutes and seconds you just do the inverse:\n\n\nd = integer(45.513163\u00b0) = 45\u00b0\n\n\nm = integer((dd - d) \u00d7 60) = 30'\n\n\nOR\n\n\nm = 45((45.513163-.513163) \u00d7 60) = 30'\n\n\ns = (dd - d - m/60) \u00d7 3600 = 47.39\"\n\n\nOR\n\n\ns = (45.513163-.513163-30/60) \u00d7 3600 = 47.39\"\n\n\n= \n45\u00b0 30' 47.39\"",
            "title": "Converting Degrees to Decimals"
        },
        {
            "location": "/Converting-Serial-dates-to-MM-DD-YYYY/",
            "text": "History Lesson\n\n\nSince the dawn of time well... before whenever now is, people have had their own opinions on what time is and how they quantify it. The vast majority of society's perception of time has revolved in some form around the revolutions of the Earth, Stars, Planets (and dwarf planets), moons, and the Sun which is technically a star but who is keeping track of all this anyways?.\n\n\nThe last few centuries ish there were really two types of calendars:\n\n\n\n\nGregorian Calendar (Tropical year is ~365.242189 days)\n\n\nThere is a leap year every year whose number is perfectly divisible by four - except for years which are both divisible by 100 and not divisible by 400, or in simpler terms, every 4 years except for every 100 except for 400, eg 1900 was not a leap year, 2000 was. 2100, 2200, 2300, are not, 2400 is. etc. \n\n\nJulian Calendar (Tropical year is 365.25 days)\n\n\nLeap year every 4 years\n\n\n\n\nWe use a Gregorian Calendar these days as its \"more accurate\" at least moreso than the Julian Calendar.\n\n\nSome Calculations\n\n\nJulian Calendar:\n\n\nCalendar Year: 365\nJulian Tropical Year: 365.25\nLeap Year: Every 4 years\n\n\n\n\nAssuming we start at 0 AD and go 2000 years:\n\n\nCalendar Year: 2000 * 365 = 730000\nTropical Year: 2000 * 365.25 = 730500\n\n\n\n\nOver 2000 years we've gained 500 days.\n\n\nTaking into account leap years:\n\n\n2000/4 = 500 Leap years\n\n\n\n\nSo if you subtract \n500\n Leap Days from the \n500\n Days extra it works out great except for the fact that the real tropical year for the earth is \n~365.242189\n which means after \n2000\n years you are \n484.38\n ahead which means that \n500-484.38 = 15.62\n \nSo you're really \n15.62 days\n ahead after \n2000 years\n or \n374.88 Hours\n or \n22492.8 Minutes\n or \n1349568 Seconds\n. Which means that you're really gaining \n674.784 seconds a year\n or \n1.85 seconds a day\n\n\nNow lets compare the Gregorian Calendar:\n\n\nGregorian Calendar:\n\n\nCalendar Year: 365\nEarth's Tropical Year: ~365.242189\nLeap Years: Every 4 years except centuries not divisible by 4\n\n\n\n\nAssuming we start at 0 AD and go 2000 years:\nCalendar Year: 2000 * 365 = 730000\nTropical Year: 2000 * 365.242189 = 730484.3781\n\n\n\n\nOver 2000 years we've gained \n~484.38 days\n which means we'd be a year and a 4 months ahead. We'd be having Summer weather during Christmas (depending on where you live on the earth as well)\n\n\nTaking into account leap years:\n\n\n2000/4 = 500 Leap years\nCenturies Divisible by 400: 2000/400 = 5\nCenturies: 2000/100 = 20\nSkipped Centuries: 20-5 = 15\n500 - 15 = 485 days\n\n\n\n\nSo based on the tropical year we gain \n484.38 days\n and when we counter in leap years we skip \n485 days\n.  so \n485-484.38 = .62\n which means after 2000 years we are \n.62 days\n ahead or \n14.88 hours\n or \n892.8 minutes\n or \n53568 seconds\n which means that on average we are only gaining \n.073 seconds per day\n. You can also factor in earth slowing its rotation and other astronomical and geological factors but generally speaking that's not terrible odds. There are even more detailed models that incorporate leap seconds but most people aren't going to live long enough to see the .073 seconds add up to anything significant so I doubt most people care enough to change the Gregorian Calendar model.  \n\n\nGranted as complicated as this may seems its actually a vast oversimplification by omitting political details. If you really want to understand the history and politics behind modern society's use of calendars the \nPerpetual Calendar\n is a good place to start.\n\n\nThe history of time is important to understand so we can understand what is happening with the dates in different packages of software:\n\n\nSoftware Nuances\n\n\nExcel\n\n\nThe underlying code in excel uses a serial number to define dates and if your cells aren't formatted as a date like \nmm/dd/yyyy\n then you'll likely see the serial date number.\n\n\nThe serial number is a form of \"Julian Date\" which in the programming world has become a bit of a misnomer as now most calendars are based on the Gregorian Calendar rather than the Julian Calendar. To simplify our definition of a Julian Date or Julian Day, it is basically a serial number of the days from the beginning of a year. To eliminate ambiguity with the terminology of Julian dates not actually being based on the Julian Calendar, it makes more sense just to call them \"ordinal dates\" or \"day of year.\" Astronomers have used a Julian date which is a count of days since noon January 1, 4713 BC which actually \nis\n based on the Julian Calendar. Excel on the other hand starts their time at January 1, 1900. \n\n\nThe problem is that they assume 1900 was a leap year but as discussed earlier the Gregorian Calendar doesn't have leap years on centuries not divisible by 4. so depending on how you run your conversions if you have dates between 1/1/1900 and 3/1/1900 you may end up being off by a day which means you'll need something like \nif x <= 60 then serialdate + 1\n to get it to convert correctly.\n\n\nFor example: 39448 is the serial number of the date 1/1/2008 or in other words 1/1/2008 is 39448 days since 1/1/1900 (including 2/29/1900)\n\n\nSee the following links for more info. but in short they historically kept the bug to be compatible with another software and now it's just too late.\n\n\nhttps://support.microsoft.com/en-us/help/214326/excel-incorrectly-assumes-that-the-year-1900-is-a-leap-year\nhttps://support.office.com/en-us/article/DATEVALUE-function-df8b07d4-7761-4a93-bc33-b7471bbff252\n\n\nExcel on the mac has its starting point at 1/1/1904 to skip the whole leap year issue.\n\n\nConvert Serial Date Field Calculator\n\n\nConvert int to long with python\n\n\nint (!field!)\n\n\nField Calculate:\n\n\ndatetime.datetime(1899, 12, 30) + datetime.timedelta(days= !StartDate! )\n\n\n\n\nOther notes: Sidereal year = 365.014172 (which calendar uses sidereal years?)",
            "title": "Converting Serial Dates"
        },
        {
            "location": "/Converting-Serial-dates-to-MM-DD-YYYY/#history-lesson",
            "text": "Since the dawn of time well... before whenever now is, people have had their own opinions on what time is and how they quantify it. The vast majority of society's perception of time has revolved in some form around the revolutions of the Earth, Stars, Planets (and dwarf planets), moons, and the Sun which is technically a star but who is keeping track of all this anyways?.  The last few centuries ish there were really two types of calendars:   Gregorian Calendar (Tropical year is ~365.242189 days)  There is a leap year every year whose number is perfectly divisible by four - except for years which are both divisible by 100 and not divisible by 400, or in simpler terms, every 4 years except for every 100 except for 400, eg 1900 was not a leap year, 2000 was. 2100, 2200, 2300, are not, 2400 is. etc.   Julian Calendar (Tropical year is 365.25 days)  Leap year every 4 years   We use a Gregorian Calendar these days as its \"more accurate\" at least moreso than the Julian Calendar.",
            "title": "History Lesson"
        },
        {
            "location": "/Converting-Serial-dates-to-MM-DD-YYYY/#some-calculations",
            "text": "",
            "title": "Some Calculations"
        },
        {
            "location": "/Converting-Serial-dates-to-MM-DD-YYYY/#julian-calendar",
            "text": "Calendar Year: 365\nJulian Tropical Year: 365.25\nLeap Year: Every 4 years  Assuming we start at 0 AD and go 2000 years:  Calendar Year: 2000 * 365 = 730000\nTropical Year: 2000 * 365.25 = 730500  Over 2000 years we've gained 500 days.  Taking into account leap years:  2000/4 = 500 Leap years  So if you subtract  500  Leap Days from the  500  Days extra it works out great except for the fact that the real tropical year for the earth is  ~365.242189  which means after  2000  years you are  484.38  ahead which means that  500-484.38 = 15.62  \nSo you're really  15.62 days  ahead after  2000 years  or  374.88 Hours  or  22492.8 Minutes  or  1349568 Seconds . Which means that you're really gaining  674.784 seconds a year  or  1.85 seconds a day  Now lets compare the Gregorian Calendar:",
            "title": "Julian Calendar:"
        },
        {
            "location": "/Converting-Serial-dates-to-MM-DD-YYYY/#gregorian-calendar",
            "text": "Calendar Year: 365\nEarth's Tropical Year: ~365.242189\nLeap Years: Every 4 years except centuries not divisible by 4  Assuming we start at 0 AD and go 2000 years:\nCalendar Year: 2000 * 365 = 730000\nTropical Year: 2000 * 365.242189 = 730484.3781  Over 2000 years we've gained  ~484.38 days  which means we'd be a year and a 4 months ahead. We'd be having Summer weather during Christmas (depending on where you live on the earth as well)  Taking into account leap years:  2000/4 = 500 Leap years\nCenturies Divisible by 400: 2000/400 = 5\nCenturies: 2000/100 = 20\nSkipped Centuries: 20-5 = 15\n500 - 15 = 485 days  So based on the tropical year we gain  484.38 days  and when we counter in leap years we skip  485 days .  so  485-484.38 = .62  which means after 2000 years we are  .62 days  ahead or  14.88 hours  or  892.8 minutes  or  53568 seconds  which means that on average we are only gaining  .073 seconds per day . You can also factor in earth slowing its rotation and other astronomical and geological factors but generally speaking that's not terrible odds. There are even more detailed models that incorporate leap seconds but most people aren't going to live long enough to see the .073 seconds add up to anything significant so I doubt most people care enough to change the Gregorian Calendar model.    Granted as complicated as this may seems its actually a vast oversimplification by omitting political details. If you really want to understand the history and politics behind modern society's use of calendars the  Perpetual Calendar  is a good place to start.  The history of time is important to understand so we can understand what is happening with the dates in different packages of software:",
            "title": "Gregorian Calendar:"
        },
        {
            "location": "/Converting-Serial-dates-to-MM-DD-YYYY/#software-nuances",
            "text": "",
            "title": "Software Nuances"
        },
        {
            "location": "/Converting-Serial-dates-to-MM-DD-YYYY/#excel",
            "text": "The underlying code in excel uses a serial number to define dates and if your cells aren't formatted as a date like  mm/dd/yyyy  then you'll likely see the serial date number.  The serial number is a form of \"Julian Date\" which in the programming world has become a bit of a misnomer as now most calendars are based on the Gregorian Calendar rather than the Julian Calendar. To simplify our definition of a Julian Date or Julian Day, it is basically a serial number of the days from the beginning of a year. To eliminate ambiguity with the terminology of Julian dates not actually being based on the Julian Calendar, it makes more sense just to call them \"ordinal dates\" or \"day of year.\" Astronomers have used a Julian date which is a count of days since noon January 1, 4713 BC which actually  is  based on the Julian Calendar. Excel on the other hand starts their time at January 1, 1900.   The problem is that they assume 1900 was a leap year but as discussed earlier the Gregorian Calendar doesn't have leap years on centuries not divisible by 4. so depending on how you run your conversions if you have dates between 1/1/1900 and 3/1/1900 you may end up being off by a day which means you'll need something like  if x <= 60 then serialdate + 1  to get it to convert correctly.  For example: 39448 is the serial number of the date 1/1/2008 or in other words 1/1/2008 is 39448 days since 1/1/1900 (including 2/29/1900)  See the following links for more info. but in short they historically kept the bug to be compatible with another software and now it's just too late.  https://support.microsoft.com/en-us/help/214326/excel-incorrectly-assumes-that-the-year-1900-is-a-leap-year\nhttps://support.office.com/en-us/article/DATEVALUE-function-df8b07d4-7761-4a93-bc33-b7471bbff252  Excel on the mac has its starting point at 1/1/1904 to skip the whole leap year issue.",
            "title": "Excel"
        },
        {
            "location": "/Converting-Serial-dates-to-MM-DD-YYYY/#convert-serial-date-field-calculator",
            "text": "Convert int to long with python  int (!field!)  Field Calculate:  datetime.datetime(1899, 12, 30) + datetime.timedelta(days= !StartDate! )  Other notes: Sidereal year = 365.014172 (which calendar uses sidereal years?)",
            "title": "Convert Serial Date Field Calculator"
        },
        {
            "location": "/Importing-Points-with-Latitude-and-Longitude/",
            "text": "Importing points based on latitude and longitude fields is a pretty common thing. Points will generally come from GPS units or Google Maps. There are a few tools in ArcMap to import X Y Data.\n\n\nYou will want to make sure your spreadsheet is clean (remove duplicates, sort out null values, CamelCase Titles, remove filters etc.)\n\n\nYou can add your data with \nFile >> Add Data >> Add XY Data\n Then you can select your spreadsheet (X field should be Longitude, Y field should be Latitude, Z field is elevation)\n\n\nIf there are problems you can try using the \nMake XY Event Layer\n\n\nDatum will usually be WGS84\n\n\nOnce your layer is created you'll export the data to a shapefile or feature class.\n\n\nYou'll need to \nproject\n it to your coordinate system if your project isn't using the GPS' datum.",
            "title": "Importing Lat Long"
        },
        {
            "location": "/Make-Query-Table/",
            "text": "When dealing with cardinality (type of data relationship: one to one, one to many, etc.) there are many ways to manage your data. You can do joins which are typically one to one or many to one (which may only pick the first match in the table) but if you need to do a one to many or many to many than you will either need to make a relationship class to handle the relationships or \nmake a query table\n which will duplicate the features.\n\n\nLooking at a real world example, I have a a database of documents that apply to many different properties. Let's quickly map out the cardinality of the data:\n\n\n\n\nSome documents only apply to one property\n\n\nSome documents apply to many properties\n\n\nSome properties have many documents\n\n\nSome properties have one document\n\n\n\n\nI know this sounds a little redundant but we have to look at the relationships from both sides of the table. I have two main tables, one for my documents, one for my properties and I've created an intermediate table which shows which documents apply to which properties. EG:\n\n\n(1) Document Table:\n\n\n\n\n\n\n\n\nOBJECTID\n\n\nDOCUMENT\n\n\n\n\n\n\n\n\n\n\n1\n\n\ndoc1\n\n\n\n\n\n\n2\n\n\ndoc2\n\n\n\n\n\n\n3\n\n\ndoc3\n\n\n\n\n\n\n4\n\n\ndoc4\n\n\n\n\n\n\n\n\n(2) Property Table:\n\n\n\n\n\n\n\n\nOBJECTID\n\n\nPARCELNUM\n\n\n\n\n\n\n\n\n\n\n1\n\n\n3600\n\n\n\n\n\n\n2\n\n\n3700\n\n\n\n\n\n\n3\n\n\n3800\n\n\n\n\n\n\n4\n\n\n3900\n\n\n\n\n\n\n\n\n(3) Intermediate Table:\n\n\n\n\n\n\n\n\nOBJECTID\n\n\nPARCELNUM\n\n\nDOCUMENT\n\n\n\n\n\n\n\n\n\n\n1\n\n\n3600\n\n\ndoc1\n\n\n\n\n\n\n2\n\n\n3700\n\n\ndoc1\n\n\n\n\n\n\n3\n\n\n3800\n\n\ndoc3\n\n\n\n\n\n\n4\n\n\n3800\n\n\ndoc4\n\n\n\n\n\n\n5\n\n\n3900\n\n\ndoc5\n\n\n\n\n\n\n\n\nFrom Table (1) to Table (2) you can see doc1 applies to two properties (one to many) but also property 3800 has two documents, doc3 and doc4 (many to one) and of course there are also properties with just one document (one to one). Because both sides of the table have a one to many or many to one relationship, if we wish to retain all the information from both tables we need to set up a many to many relationship. Typically this would be done with a relationship class but for this exercise instead of creating a relationship class we are going to create a query layer that will duplicate the features instead while retaining the relevant attributes.\n\n\n\n\nCatalog\n >> \nSystem Toolboxes\n >> \nData Management Tools\n >> \nLayers and Table Views\n >> \nMake Query Layer\n (or you can just search for Make Query Layer, its faster)\n\n\n\n\nYou'll notice that the expression field doesn't have quotation marks like all the examples on ESRI. For some reason the expression only works if it DOESN'T have quotation marks.\n\n\n\n\nThis is the original properties layer:\n\n\n\n\nThis is the query Table Layer, notice how property 3800 was duplicated (due to it having two different documents on that property):",
            "title": "Query Table"
        },
        {
            "location": "/Parsing-KML-HTML-Tables/",
            "text": "Copy all rows in description field and paste in online validator such as \nthis\n and that will remove all the tags and then paste into notepad++\n\n\nMark All Fields:\n\n\nGo to Search menu > Find... > Select \"Mark\" Tab. Activate regular expressions. Search for ^\n (^ is for line start). Don't forget to check \"Bookmark lines\" and Press \"Mark All\"\n\n\n==> All Rows you want to keep got a Bookmark\nGo to Menu \"Search - Bookmark - Inverse Bookmark\"\n\n\n==> All Line you want to delete are bookmarked.\nGo to Menu \"Search - Bookmark - Remove Bookmarked lines\"\n\n\n==> All Bookmarked lines are deleted.\n\n\nhold ctrl+alt while selecting to select vertical columns to delete sections of data\n\n\nthen you can paste back into a spreadsheet, save that spreadsheet as a csv and then join that to your data and field calculate new fields.",
            "title": "Parsing KML HTML Tables"
        },
        {
            "location": "/Select-By-Attributes/",
            "text": "A simple way to query data is through the \nselect by attributes\n tool. It uses SQL to filter results.\n\n\nIf you want to query for a part of a string\n\n\nFIELD LIKE '%pattern%'\n\n\n\n\nQuery For Forward Slashes:\n\n\nFIELD LIKE '%/%'",
            "title": "Select By Attributes"
        },
        {
            "location": "/Select-By-Location/",
            "text": "Select by location lets you select certain features based on the physical locations of others. For example lets say I have some poles for a transmission line and I want to find out which properties they are on. I could also do an intersection but maybe I don't want to create a new feature class and I just want to generate a list from the attribute table.\n\n\n\n\nSelection\n >> \nSelect By Location\n\n\nTarget layer is the layer you want selected\n\n\nSource layer is the layer you are using to select the target layer\n\n\nSpatial selection method (basically different variables of intersection)\n\n\nApply a search distance allows you to have a defined selection buffer if you want more than just what is intersected.\n\n\n\n\nThe following is an example of using power poles to select the parcels they are on.\n\n\n\n\nand this is the result:",
            "title": "Select By Location"
        },
        {
            "location": "/Spatial-Join/",
            "text": "There are a myriad of ways to combine the attributes of multiple features. A Spatial Join is basically a more permanent \nSelect By Location\n.\n\n\nFor example lets say I have a bunch of trees and every gardener has an area to maintain and you'd like to know how many trees each gardener is responsible for. You can use a spatial join to add the gardener's name to each tree.\n\n\nOr maybe you have a bunch of points for landowners but you want to get the parcel data from a tax map, a spatial join will help you do that as well.\n\n\n\n\nTarget Features\n (The feature you want to add attributes to): Land Owner Points\n\n\nJoin Features\n (The features you get your attributes from): Tax Map Attributes\n\n\nOutput Feature Class\n: LandOwnerJoined\n\n\nJoin Operation\n: One to One\n\n\n\n\nIf everything went according to plan you'll have your point layer with the underlying property's attributes.",
            "title": "Spatial Join"
        },
        {
            "location": "/Table-to-Relationship-Class/",
            "text": "Generally you'll want to use relationship classes when you have a many to many relationship between two tables. \n\n\nFor example I have a map of properties and I have a database of documents that correspond to the properties on my map.\n\n\n\n\nSome documents correspond to one property\n\n\nSome documents correspond to multiple properties\n\n\nSome properties correspond to one document\n\n\nSome properties correspond to many documents\n\n\n\n\nbecause multiple properties can correspond to multiple documents and vice versa, we have a many to many relationship.\n\n\nThe following tables are an example of the data. The Document Table has all of my documents, the Property Table is the attribute table of my property feature class, and I've created an intermediate table showing which documents correspond to which properties (though the intermediate table could also be automatically generated as part of making a relationship class assuming the tables had the relevant fields to match.)\n\n\n(1) Document Table:\n\n\n\n\n\n\n\n\nOBJECTID\n\n\nDOCUMENT\n\n\n\n\n\n\n\n\n\n\n1\n\n\ndoc1\n\n\n\n\n\n\n2\n\n\ndoc2\n\n\n\n\n\n\n3\n\n\ndoc3\n\n\n\n\n\n\n4\n\n\ndoc4\n\n\n\n\n\n\n\n\n(2) Property Table:\n\n\n\n\n\n\n\n\nOBJECTID\n\n\nPARCELNUM\n\n\n\n\n\n\n\n\n\n\n1\n\n\n3600\n\n\n\n\n\n\n2\n\n\n3700\n\n\n\n\n\n\n3\n\n\n3800\n\n\n\n\n\n\n4\n\n\n3900\n\n\n\n\n\n\n\n\n(3) Intermediate Table:\n\n\n\n\n\n\n\n\nOBJECTID\n\n\nPARCELNUM\n\n\nDOCUMENT\n\n\n\n\n\n\n\n\n\n\n1\n\n\n3600\n\n\ndoc1\n\n\n\n\n\n\n2\n\n\n3700\n\n\ndoc1\n\n\n\n\n\n\n3\n\n\n3800\n\n\ndoc3\n\n\n\n\n\n\n4\n\n\n3800\n\n\ndoc4\n\n\n\n\n\n\n5\n\n\n3900\n\n\ndoc5\n\n\n\n\n\n\n\n\n\n\nToolboxes\n >> \nSystem Toolboxes\n >> \nData Management Tools\n >> \nRelationship Classes\n >> \nTable to Relationship Class\n (or you can just search for Table to Relationship class, its faster)\n\n\nOrigin table will generally be your feature\n\n\nDestination table is the table you want to be returned when identifying the feature\n\n\nOutput relationship class is the file geodatabase where you want it saved\n\n\nRelationship type in this case will be simple\n\n\nForward path label (Destination Table)\n\n\nBackward path label (Origin Table)\n\n\nMessage direction (if you want edits propagated to the other tables you'll want something other than none)\n\n\nCardinality (many to many)\n\n\nRelationship Table: this is our intermediate table we defined\n\n\nAttribute fields. check the attributes you wish to keep\n\n\nOrigin Primary Key (unique field from Origin Table (feature))\n\n\nOrigin Foreign Key (Unique field from Intermediate table (feature))\n\n\nDestination Primary Key (Unique field from destination table (docs))\n\n\nDestination Foreign Key (Unique field from Intermediate Table (document))\n\n\n\n\n\n\nUnlike when we created a query table, this time the features aren't duplicated, rather one feature shows a related table of both documents that correspond to that property.",
            "title": "Table to Relationship Class"
        },
        {
            "location": "/Field-Calculator-Python-If-Then-Statements/",
            "text": "When doing field calculations sometimes you'll want to modify certain fields and not others, an if then statement can help with that. Lets say we have a table where some characters are numbers and some are letters and we want to find all the numeric values and replace them with blank fields.\n\n\nLets write out what we want to happen in basic readable text:\n\n\nif field is a number\nreturn a blank field\notherwise (else)\nreturn the original field\n\n\n\n\nNow lets turn what we want to happen into code:\n\n\nThis is the content we put in the Pre-Logic Script Code:\n\n\ndef CheckNumber(field):\n    if (field.isdigit()):\n      return \"\"\n    else:\n      return field\n\n\n\n\nField =\n\n\nCheckNumber(!Field1!)\n\n\n\n\nThis is how it looks in the field calculator\n\n\n\n\nIt turns this:\n\n\n| Field |\n| :---: |\n|   A   |\n|   5   |\n|   F   |\n\n\ninto \n\n\n| Field |\n| :---: |\n|   A   |\n|       |\n|   F   |\n\n\nIf then statements can be a very useful tool when you need more control over how your data changes when using the field calculator.",
            "title": "If Then Statements"
        },
        {
            "location": "/Field-Calculator-Python-Joining-Concatenation/",
            "text": "Sometimes you'll want to join multiple fields together but it is important to be aware of the stipulations.\n\n\nIf you are using python to join fields the syntax is \n!Field1! + !Field2!\n: very simple, BUT the \n+\n is also used in basic arithmetic operations, so lets say Field1 was a \n5\n and Field2 was a \n2\n do you want it to return \n52\n or \n7\n? Because Python can't read your mind you need to tell it exactly what you want it to do.\n\n\nYou can add fields together as long as the data types are all the same (eg adding two text fields \nhot\n and \ndog\n will yield \nhotdog\n) If you want to add a integer field with a text field Python won't be too happy with you based on the syntax mentioned above so you have a couple options.\n\n\nOption 1:\n\n\nYou can create a new field with the text data type and put in your numbers and they will join happily with your text values\n\n\n`!Field1! + !Field2!`\n\n\n\n\nOption 2:\n\n\nYou can cast your non-string field as a string as part of the join so you won't need to create a new field\n\n\n\"\".join([str(i) for i in [!field1!, !field2!, !field3!] if i])\n\n\n\n\nWhatever is set inside the first quotation marks is defined as your delimiter, so if you want each field to be separated by spaces, add a space.",
            "title": "Joining and Concatenation"
        },
        {
            "location": "/Field-Calculator-Python-Slicing/",
            "text": "When using the field calculator, parsing strings in various formats is a pretty common practise. Slicing strings is a little different than other parsing methods in that you are slicing in between characters rather than selecting a number of characters. The following is a simple graphic illustrating slicing:\n\n\n +---+---+---+---+---+---+\n | P | Y | T | H | O | N |\n +---+---+---+---+---+---+\n 0   1   2   3   4   5   6\n-6  -5  -4  -3  -2  -1   0 \n\n\n\n\nNote that there are some syntax variances with pure python compared to arc python but the principles are the same, as this is a GIS-centric blog I will use examples from the syntax within the field calculator\n\n\nReturn first character:\n\n\n!field![1:]\n\n\n\n\nResult: \nP\n\n\nReturn last 5 characters:\n\n\n!field![-5:]\n\n\n\n\nResult: \nYTHON\n\n\nReturn characters 2 and 3:\n\n\n!field![1:3]\n\n\n\n\nResult: \nYT",
            "title": "Slicing"
        },
        {
            "location": "/Field-Calculator-Python-String-Manipulation/",
            "text": "Sometimes you'll want to compare two fields but the formats are just slightly different. You can use python to manipulate the strings so they both have the same format and will yield more accurate results when comparing two fields.\n\n\nFind and Replace\n\n\nThere are a few ways to do a find and replace. You can click on the table options in the attribute table and select find and replace and use the gui there.\n\n\nYou can also use the \n.replace\n function in the field calculator:\n\n\n!FIELD!.replace(\"Find\",\"Replace\")\n\n\n\n\nSo if I had a field with \n_\n and I want to replace them all with \n-\n then it would be:\n\n\n!FIELD!.replace(\"_\",\"-\")\n\n\n\n\nOf course you can also use an if then statement in the field calculator in order to have a little more flexibility in the results.\n\n\nCase Sensitivity\n\n\nSometimes programs are picky about case sensitivity, python makes it easy to convert the cases.\n\n\nIf I want to make all the letters lowercase:\n\n\n!Field! .lower()\n\n\n\n\nIf I want to make all the letters uppercase:\n\n\n!Field! .upper()",
            "title": "String Manipulation"
        },
        {
            "location": "/Field-Calculator-Python-String-Manipulation/#find-and-replace",
            "text": "There are a few ways to do a find and replace. You can click on the table options in the attribute table and select find and replace and use the gui there.  You can also use the  .replace  function in the field calculator:  !FIELD!.replace(\"Find\",\"Replace\")  So if I had a field with  _  and I want to replace them all with  -  then it would be:  !FIELD!.replace(\"_\",\"-\")  Of course you can also use an if then statement in the field calculator in order to have a little more flexibility in the results.",
            "title": "Find and Replace"
        },
        {
            "location": "/Field-Calculator-Python-String-Manipulation/#case-sensitivity",
            "text": "Sometimes programs are picky about case sensitivity, python makes it easy to convert the cases.  If I want to make all the letters lowercase:  !Field! .lower()  If I want to make all the letters uppercase:  !Field! .upper()",
            "title": "Case Sensitivity"
        },
        {
            "location": "/COGO/",
            "text": "COGO tools stand for Coordinate Geometry and is a set of tools for drawing survey data in GIS.\n\n\nFor more information on COGO see \nHERE",
            "title": "COGO"
        },
        {
            "location": "/COGO-Tools:-Drawing-Lines/",
            "text": "Many official documents that involve property will have surveys or references to documents with surveys. Some might have sketches or diagrams but there are many that only have a written legal description. COGO tools enables you to map out the written legal descriptions.\n\n\nSetting the Stage\n\n\nHow you configure COGO Tools largely depends on the type of survey you are trying to map. Generally it falls into two categories.\n\n\n\n\nCenter Line\n\n\nArea\n\n\n\n\nA survey describing a center line will typically be described something like \"Being a strip of land six (6) feet in width extending three (3) feet on each side of a center line...\" then it will typically follow the calls until the endpoint then we can just buffer out the centerline the labeled distance to create the final polygon.\n\n\nA survey describing an area will typically have a point of beginning and then it will follow out its calls and then end right back up at the point of beginning so it is a closed polygon. \n\n\nUnits and Bearings\n\n\nSee ESRI's documentation \nHERE\n\n\nDepending on how old the document is and where you are in the world it might describe calls in units of feet, metres, or chains and rods. Generally people nowadays in the United States use a HARN stateplane coordinate system (which is Feet or International Feet) which will also typically match any U.S. CAD based surveys as those are usually in feet as well. \n\n\nBearings are also described in a myriad of ways: Polar, North Azimuth, South Azimuth, or Quadrant Bearing. Most of the documents I've seen are Quadrant bearings. \n\n\nYou can change your units through the editor toolbar\n\n\n\n\nCustomize >> Toolbars >> Editor\n\n\n\n\n\n\n\n\nClick the editor dropdown and select \nOptions\n\n\nClick on the \nUnits\n tab\n\n\nChange \nDirection Type\n to \nQuadrant Bearing\n\n\nChange \nDirection Units\n to \nDegrees Minutes Seconds\n \n\n\n\n\n\n\nThe example I'm going to be using is in Oregon based on the Oregon Stateplane North Coordinate System (EPSG 2913) with a line feature class\n\n\nThe Legal Description\n\n\nThe following is taken from a typical legal description:\n\n\n\"... assigns a perpetual easement and right of way under and across the following described parcel of land situated in Multnomah County, Oregon being a strip of land six (6) feet in width extending three (3) feet on each side of a center line more particularly described as follows:\"\n\n\nBeginning at a point on the South line of the North 89 feet of Lot 11, PEAKE BROTHERS HOME TRACTS, located in Section 32,\nTownship 1 North, Range 3 East, Willamette Meridian, said point begin East 22.97 feet from the West line of said Lot 11;\nRUNNING THENCE South 84 Degrees, 35 Minutes, and 35 Seconds East 91.67 feet; THENCE South 6 Degrees, 32 Minutes, and 45 Seconds West 65.52 feet; \nTHENCE South 3 Degrees, 24 Minutes, and 15 Seconds East 57 feet, more or less, to a point on the South line of Lot 10\n\n\n\n\nThe legal description has a lot of words, so lets simplify it into just the calls:\n\n\nN 89-58-53 E 22.97 (the bearing was generated from the property line of my parcel data)\nS 84-35-35 E 91.67\nS 06-32-45 W 65.52\nS 03-24-15 E 57.00\n\n\n\n\nSometimes the hardest part about a legal description is finding the basepoint, once the basepoint has been found, drawing out the calls is a simple enough task. I was able to find a GIS dataset of the county parcels along with a \npdf assessor map\n that shows me the neighbourhood and lot listed in the legal description. For the purposes of this exercise the basepoint is \n[7698024.236,  681995.698]\n equivalent in lat long is \nLAT: 122\u00b028'0.72\"W LONG: 45\u00b031'13.782\"N\n\n\nDrawing a Traverse\n\n\nAssuming you have your respective feature class created with the correct coordinate system we can now get started\n\n\n\n\nAdd COGO toolbar: Customize >> Toolbars >> COGO\n\n\n\n\n\n\n\n\nSelect the traverse icon \n\n\n\n\n\n\n\n\nSelect your basepoint (You can click on a location on a map or type in coordinates)\n\n\n\n\n\n\nThen we start by typing in our direction and distance for each call (see also \nESRI docs\n. Once we have finished all of the calls it will look something like this:\n\n\n\n\n\n\nDon't forget we aren't quite finished, since this is a center line and it really is describing a width we need to buffer it out the described 3 feet on either side:\n\n\n\n\nSave Traverse\n\n\nWe can also right click and save as a text file for future reference if we need to reload it, otherwise you can just click finish and it wills save your feature. \n\n\nThe saved traverse text file looks something like this \ntraverse.txt\n\n\nDT QB\nDU DMS\nSP 7698024.236 681995.698\nDD N89-58-53E 22.97\nDD S84-35-35E 91.67\nDD S6-32-45W 65.52\nDD S3-24-15E 57\n\n\n\n\nDT: quadrant bearing, DU: degrees, minutes, seconds, SP: starting point (x,y), DD direction/distance (FT) You can also right click in the traverse window and load the above text file\n\n\nLoad Traverse From Sketch\n\n\nIf you want to generate a traverse based on something that you have drawn you can select your feature, right click and select \nedit vertices\n, then within the traverse window you can right click and select \nload traverse from sketch\n and it will generate calls for all of the lines. This is by no means a replacement for an actual survey but it can help give you context.",
            "title": "COGO Tools Drawing Lines"
        },
        {
            "location": "/COGO-Tools:-Drawing-Lines/#setting-the-stage",
            "text": "How you configure COGO Tools largely depends on the type of survey you are trying to map. Generally it falls into two categories.   Center Line  Area   A survey describing a center line will typically be described something like \"Being a strip of land six (6) feet in width extending three (3) feet on each side of a center line...\" then it will typically follow the calls until the endpoint then we can just buffer out the centerline the labeled distance to create the final polygon.  A survey describing an area will typically have a point of beginning and then it will follow out its calls and then end right back up at the point of beginning so it is a closed polygon.",
            "title": "Setting the Stage"
        },
        {
            "location": "/COGO-Tools:-Drawing-Lines/#units-and-bearings",
            "text": "See ESRI's documentation  HERE  Depending on how old the document is and where you are in the world it might describe calls in units of feet, metres, or chains and rods. Generally people nowadays in the United States use a HARN stateplane coordinate system (which is Feet or International Feet) which will also typically match any U.S. CAD based surveys as those are usually in feet as well.   Bearings are also described in a myriad of ways: Polar, North Azimuth, South Azimuth, or Quadrant Bearing. Most of the documents I've seen are Quadrant bearings.   You can change your units through the editor toolbar   Customize >> Toolbars >> Editor     Click the editor dropdown and select  Options  Click on the  Units  tab  Change  Direction Type  to  Quadrant Bearing  Change  Direction Units  to  Degrees Minutes Seconds      The example I'm going to be using is in Oregon based on the Oregon Stateplane North Coordinate System (EPSG 2913) with a line feature class",
            "title": "Units and Bearings"
        },
        {
            "location": "/COGO-Tools:-Drawing-Lines/#the-legal-description",
            "text": "The following is taken from a typical legal description:  \"... assigns a perpetual easement and right of way under and across the following described parcel of land situated in Multnomah County, Oregon being a strip of land six (6) feet in width extending three (3) feet on each side of a center line more particularly described as follows:\"  Beginning at a point on the South line of the North 89 feet of Lot 11, PEAKE BROTHERS HOME TRACTS, located in Section 32,\nTownship 1 North, Range 3 East, Willamette Meridian, said point begin East 22.97 feet from the West line of said Lot 11;\nRUNNING THENCE South 84 Degrees, 35 Minutes, and 35 Seconds East 91.67 feet; THENCE South 6 Degrees, 32 Minutes, and 45 Seconds West 65.52 feet; \nTHENCE South 3 Degrees, 24 Minutes, and 15 Seconds East 57 feet, more or less, to a point on the South line of Lot 10  The legal description has a lot of words, so lets simplify it into just the calls:  N 89-58-53 E 22.97 (the bearing was generated from the property line of my parcel data)\nS 84-35-35 E 91.67\nS 06-32-45 W 65.52\nS 03-24-15 E 57.00  Sometimes the hardest part about a legal description is finding the basepoint, once the basepoint has been found, drawing out the calls is a simple enough task. I was able to find a GIS dataset of the county parcels along with a  pdf assessor map  that shows me the neighbourhood and lot listed in the legal description. For the purposes of this exercise the basepoint is  [7698024.236,  681995.698]  equivalent in lat long is  LAT: 122\u00b028'0.72\"W LONG: 45\u00b031'13.782\"N",
            "title": "The Legal Description"
        },
        {
            "location": "/COGO-Tools:-Drawing-Lines/#drawing-a-traverse",
            "text": "Assuming you have your respective feature class created with the correct coordinate system we can now get started   Add COGO toolbar: Customize >> Toolbars >> COGO     Select the traverse icon      Select your basepoint (You can click on a location on a map or type in coordinates)    Then we start by typing in our direction and distance for each call (see also  ESRI docs . Once we have finished all of the calls it will look something like this:    Don't forget we aren't quite finished, since this is a center line and it really is describing a width we need to buffer it out the described 3 feet on either side:",
            "title": "Drawing a Traverse"
        },
        {
            "location": "/COGO-Tools:-Drawing-Lines/#save-traverse",
            "text": "We can also right click and save as a text file for future reference if we need to reload it, otherwise you can just click finish and it wills save your feature.   The saved traverse text file looks something like this  traverse.txt  DT QB\nDU DMS\nSP 7698024.236 681995.698\nDD N89-58-53E 22.97\nDD S84-35-35E 91.67\nDD S6-32-45W 65.52\nDD S3-24-15E 57  DT: quadrant bearing, DU: degrees, minutes, seconds, SP: starting point (x,y), DD direction/distance (FT) You can also right click in the traverse window and load the above text file",
            "title": "Save Traverse"
        },
        {
            "location": "/COGO-Tools:-Drawing-Lines/#load-traverse-from-sketch",
            "text": "If you want to generate a traverse based on something that you have drawn you can select your feature, right click and select  edit vertices , then within the traverse window you can right click and select  load traverse from sketch  and it will generate calls for all of the lines. This is by no means a replacement for an actual survey but it can help give you context.",
            "title": "Load Traverse From Sketch"
        },
        {
            "location": "/COGO-Tools:-Labeling-Lines/",
            "text": "Generally speaking when it comes to surveying, most exhibits are done in AutoCAD, but lets say you're using GIS and you want to provide an exhibit with all the same information such as the survey calls, bearings, distances etc. You could use a \nparcel fabric\n but if you're just trying to make one exhibit that may be too involved and you might not have the correct dataset. You can use a \ndimension feature class\n but they take a bit of work to get the styling right and even then you are only getting distances, not bearings (at least not without some interesting field calculations). The other solution is to add COGO attributes to your lines - this way you can set up label expressions to not only include distances but bearings as well.\n\n\nI'm going to assume you know how to create a line feature class and that you've already done it. I'm also going to assume you know how to use COGO tools to create a traverse.\n\n\nAdd COGO Attributes\n\n\nYou have your line you want to label with survey calls. First we need to add COGO attributes.\n- Open ArcCatalog\n- Go to the top \nCustomize\n toolbar and choose \nCustomize Mode\n\n\n\n\n\n\nClick \nNew\n and name it \nCOGO\n\n\nSelect the \nCommands\n tab and search for \nCOGO\n\n\nDrag the \nCreate COGO Fields\n to the COGO toolbar you created\n\n\n\n\n\n\n\n\nNavigate to your line feature class and click on it once to highlight it\n\n\nClick the \nCreate COGO Fields\n button (Make sure that you are not in an open edit session and that your features aren't active!)\n\n\nIf it is successful it will pop up with a message saying your fields have been created. \n\n\n\n\n\n\n\n\nYou can verify this by checking the fields in your feature class, it will have Direction, Distance, Delta, Radius, Tangent, ArcLength, and Side.\n\n\n\n\n\n\nUpdate COGO Attributes\n\n\nOnce you've added the COGO Fields to your feature class, you can update your fields with the COGO Tools toolbar.\n\n\n\n\nSelect the Lines you want to add COGO attributes to\n\n\nClick the \nUpdate COGO Attributes\n button \n\n\n\n\n\n\n\n\n\n\nIf you get the following warning it's a polyline or something else but you can use the \nSplit Line at Vertices\n tool) or you can use the \nsplit into COGO line\n tool \n\n\n\n\n\n\n\nThis is what my drawing looks like now:\n\n\n\n\nLabel COGO Fields\n\n\n\n\nOpen your \nLayer properties\n\n\nSelect the \nlabel\n tab\n\n\n\n\n\n\n\n\nCheck \nLabel features in this layer\n\n\nMethod \nLabel all the features the same way\n\n\nClick \nExpression\n\n\nChoose the python parser and add \n[Direction] + \"\\n\" + [Distance]\n\n\n\n\n\n\n\n\nIn placement properties for the maplex engine I chose street address placement without stacking labels. You can play with the labeling to find out what will work best for the layout of your own map.",
            "title": "COGO Tools Labeling Lines"
        },
        {
            "location": "/COGO-Tools:-Labeling-Lines/#add-cogo-attributes",
            "text": "You have your line you want to label with survey calls. First we need to add COGO attributes.\n- Open ArcCatalog\n- Go to the top  Customize  toolbar and choose  Customize Mode    Click  New  and name it  COGO  Select the  Commands  tab and search for  COGO  Drag the  Create COGO Fields  to the COGO toolbar you created     Navigate to your line feature class and click on it once to highlight it  Click the  Create COGO Fields  button (Make sure that you are not in an open edit session and that your features aren't active!)  If it is successful it will pop up with a message saying your fields have been created.      You can verify this by checking the fields in your feature class, it will have Direction, Distance, Delta, Radius, Tangent, ArcLength, and Side.",
            "title": "Add COGO Attributes"
        },
        {
            "location": "/COGO-Tools:-Labeling-Lines/#update-cogo-attributes",
            "text": "Once you've added the COGO Fields to your feature class, you can update your fields with the COGO Tools toolbar.   Select the Lines you want to add COGO attributes to  Click the  Update COGO Attributes  button       If you get the following warning it's a polyline or something else but you can use the  Split Line at Vertices  tool) or you can use the  split into COGO line  tool     This is what my drawing looks like now:",
            "title": "Update COGO Attributes"
        },
        {
            "location": "/COGO-Tools:-Labeling-Lines/#label-cogo-fields",
            "text": "Open your  Layer properties  Select the  label  tab     Check  Label features in this layer  Method  Label all the features the same way  Click  Expression  Choose the python parser and add  [Direction] + \"\\n\" + [Distance]     In placement properties for the maplex engine I chose street address placement without stacking labels. You can play with the labeling to find out what will work best for the layout of your own map.",
            "title": "Label COGO Fields"
        },
        {
            "location": "/Creating-a-Parcel-Fabric-from-Polygons/",
            "text": "Parcel Data is useful in GIS for finding ownership, tax numbers, statistics, pretty much anything with data analysis but when it comes to surveying and easements it is important to be able to see the bearings and distances of boundaries and lines. \n\n\nMany counties won't even release parcel data (unless you pay for it) data will also be omitted. If you do get it from the county it will most likely be a shapefile. If you are trying to label polygons, you won't be able to label the perimeter without creating lines. A parcel fabric is a set of features and tables that includes all of the information related to a property: Parcel numbers, boundary lines, control points, bearings and distances, areas, etc. \n\n\nProvided you have clean polygons the process is relatively simple to convert a set of polygons into a parcel fabric. In simple terms you'll convert your polygons to lines, create a topology making sure there are no overlaps etc. and then you'll load it into a parcel fabric.\n\n\nShapefile\n\n\n\n\nParcel Fabric\n\n\n\n\nCounty Map\n\n\n\n\nSetting the stage:\n\n\nCreate New Parcel Fabric:\n\n\nFirst we'll create a new parcel fabric. Create a feature dataset in a file geodatabase. Right click on the feature dataset and create new parcel fabric.\n\n\n\n\nFile Geodatabase >> \n\n\nFeature Dataset >> \n\n\nParcel Fabric\n\n\n\n\n\n\n\n\nCreate Polygon Feature Class:\n\n\nYou'll want to have your polygon layer as a feature class in a feature dataset\n\n\n\n\nFile Geodatabase >> \n\n\nFeature Dataset >> \n\n\nParcel Fabric\n\n\nPolygons\n\n\n\n\n\n\n\n\nConvert Polygons to Lines\n\n\nConvert the polygons to lines with wouldn't you know it \nPolygon to Line\n\n\n\n\nFile Geodatabase >> \n\n\nFeature Dataset >> \n\n\nParcel Fabric\n\n\nPolygons\n\n\nLines\n\n\n\n\n\n\n\n\nCreate Topology\n\n\nThen You'll create a topology in your Feature dataset which will include both the polygon and line feature classes with the following rules:\n\n\n\n\n[Line feature class] Must Be Covered By Boundary Of [Polygon feature class].\n\n\n[Line feature class] Must Not Self-Overlap.\n\n\n[Line feature class] Must Not Self-Intersect.\n\n\n[Line feature class] Must Be Single Part.\n\n\n[Line feature class] Must Not Intersect Or Touch Interior.\n\n\n[Polygon feature class] Boundary Must Be Covered By [Line feature class].\n\n\n\n\nValidate and fix any errors.\n\n\n\n\nFile Geodatabase >> \n\n\nFeature Dataset >> \n\n\nParcel Fabric\n\n\nPolygons\n\n\nLines\n\n\nTopology\n\n\n\n\n\n\n\n\nAttribute Matching\n\n\nIf you want any of your polygon's attributes to carry over then you'll need to do some field matching. The default parcel fabric fields are listed \nHERE\n. In my case I primarily care about the APN or parcel number, but I also want to add Owner information which isn't a default field in the parcel fabric, but no matter- just make sure that whatever field you want transferred over on the import that there is the same field in the parcel fabric.\n\n\nSo I changed my \nAPN\n field on my polygon layer to \nNAME\n so my parcel fabric polygons will have parcel numbers. I then created an \nOWNER\n field in the parcel fabric polygon layer so that it would be populated when I imported my polygon layer. \n\n\nLoad Topology to a Parcel Fabric\n\n\nOnce you've validated your topology and created modified all your attribute fields as you like them, then you can load the topology to the parcel fabric with again wouldn't you know it \nLoad Topology To a Parcel Fabric\n\n\nIf you did everything right then your parcel fabric will be beautiful, lines will have bearings and distances, polygons will have parcel numbers and owners.\n\n\nGranted labeling the parcel fabric is enough for another post on its own but now labeling is a possibility.",
            "title": "Creating a Parcel Fabric"
        },
        {
            "location": "/Creating-a-Parcel-Fabric-from-Polygons/#setting-the-stage",
            "text": "",
            "title": "Setting the stage:"
        },
        {
            "location": "/Creating-a-Parcel-Fabric-from-Polygons/#create-new-parcel-fabric",
            "text": "First we'll create a new parcel fabric. Create a feature dataset in a file geodatabase. Right click on the feature dataset and create new parcel fabric.   File Geodatabase >>   Feature Dataset >>   Parcel Fabric",
            "title": "Create New Parcel Fabric:"
        },
        {
            "location": "/Creating-a-Parcel-Fabric-from-Polygons/#create-polygon-feature-class",
            "text": "You'll want to have your polygon layer as a feature class in a feature dataset   File Geodatabase >>   Feature Dataset >>   Parcel Fabric  Polygons",
            "title": "Create Polygon Feature Class:"
        },
        {
            "location": "/Creating-a-Parcel-Fabric-from-Polygons/#convert-polygons-to-lines",
            "text": "Convert the polygons to lines with wouldn't you know it  Polygon to Line   File Geodatabase >>   Feature Dataset >>   Parcel Fabric  Polygons  Lines",
            "title": "Convert Polygons to Lines"
        },
        {
            "location": "/Creating-a-Parcel-Fabric-from-Polygons/#create-topology",
            "text": "Then You'll create a topology in your Feature dataset which will include both the polygon and line feature classes with the following rules:   [Line feature class] Must Be Covered By Boundary Of [Polygon feature class].  [Line feature class] Must Not Self-Overlap.  [Line feature class] Must Not Self-Intersect.  [Line feature class] Must Be Single Part.  [Line feature class] Must Not Intersect Or Touch Interior.  [Polygon feature class] Boundary Must Be Covered By [Line feature class].   Validate and fix any errors.   File Geodatabase >>   Feature Dataset >>   Parcel Fabric  Polygons  Lines  Topology",
            "title": "Create Topology"
        },
        {
            "location": "/Creating-a-Parcel-Fabric-from-Polygons/#attribute-matching",
            "text": "If you want any of your polygon's attributes to carry over then you'll need to do some field matching. The default parcel fabric fields are listed  HERE . In my case I primarily care about the APN or parcel number, but I also want to add Owner information which isn't a default field in the parcel fabric, but no matter- just make sure that whatever field you want transferred over on the import that there is the same field in the parcel fabric.  So I changed my  APN  field on my polygon layer to  NAME  so my parcel fabric polygons will have parcel numbers. I then created an  OWNER  field in the parcel fabric polygon layer so that it would be populated when I imported my polygon layer.",
            "title": "Attribute Matching"
        },
        {
            "location": "/Creating-a-Parcel-Fabric-from-Polygons/#load-topology-to-a-parcel-fabric",
            "text": "Once you've validated your topology and created modified all your attribute fields as you like them, then you can load the topology to the parcel fabric with again wouldn't you know it  Load Topology To a Parcel Fabric  If you did everything right then your parcel fabric will be beautiful, lines will have bearings and distances, polygons will have parcel numbers and owners.  Granted labeling the parcel fabric is enough for another post on its own but now labeling is a possibility.",
            "title": "Load Topology to a Parcel Fabric"
        },
        {
            "location": "/Labeling-a-Parcel-Fabric-with-the-Maplex-Engine/",
            "text": "When labeling thousands of features automation is required to maintain your sanity. Annotations are nice but they don't scale. The Maplex Engine has many helpful rules and algorithms to aesthetically label many features.\n\n\nThe options for labeling parcel fabrics are endless. For my purposes I am mostly concerned about parcel numbers, bearings, and distances. \n\n\nLabeling Lines\n\n\nLabel Position\n\nRegular Placement Straight and offset from line\n\n\nFitting Strategy\n\nOnly have reduced font size checked with a lower limit of 5 points\n\n\nLabel Density\n\nLabel buffer: 15\n\n\nConflict Resolution\n\nFeature weight: 600\n\n\nIn the attribute table for my lines layer I modified the distance field properties to round to two decimal places.\n\n\nYou can also do some expressions and rule based rendering to label the line with a bearing above and the distance below.\n\n\nI used the Straight and centered on line placement with the following label expression:\n\n\n[Distance] + \"\\n\" + [Bearing] \n\n\n\n\n\n\ncould be cleaner with some tweaks but gets the information I need.\n\n\nLabeling Polygons\n\n\nSet to land parcel placement and tweak as necessary.\n\n\nI have full parcel numbers but the lot number is only the last 5 digits and that is all I want to show in my map. I used a python expression to slice the last five characters. Make sure the python parser is selected and the advanced box is checked\n\n\ndef FindLabel ( [Name] ):\n  return [Name][-5:]",
            "title": "Label Parcel Fabric"
        },
        {
            "location": "/Labeling-a-Parcel-Fabric-with-the-Maplex-Engine/#labeling-lines",
            "text": "Label Position \nRegular Placement Straight and offset from line  Fitting Strategy \nOnly have reduced font size checked with a lower limit of 5 points  Label Density \nLabel buffer: 15  Conflict Resolution \nFeature weight: 600  In the attribute table for my lines layer I modified the distance field properties to round to two decimal places.  You can also do some expressions and rule based rendering to label the line with a bearing above and the distance below.  I used the Straight and centered on line placement with the following label expression:  [Distance] + \"\\n\" + [Bearing]    could be cleaner with some tweaks but gets the information I need.",
            "title": "Labeling Lines"
        },
        {
            "location": "/Labeling-a-Parcel-Fabric-with-the-Maplex-Engine/#labeling-polygons",
            "text": "Set to land parcel placement and tweak as necessary.  I have full parcel numbers but the lot number is only the last 5 digits and that is all I want to show in my map. I used a python expression to slice the last five characters. Make sure the python parser is selected and the advanced box is checked  def FindLabel ( [Name] ):\n  return [Name][-5:]",
            "title": "Labeling Polygons"
        },
        {
            "location": "/QGIS:-QTiles/",
            "text": "A simple way for creating mbtiles is the \nQtiles Plugin\n for QGIS.\n\n\nInstallation\n\n\n\n\nPlugin Manager\n\n\nEnable Experimental Plugins\n\n\nInstall Qtiles\n\n\n\n\nUsage\n\n\nCreate your GIS project in QGIS as you want it displayed and then access the qtiles plugin from the plugin menu at the top.\n\n\nBasemaps\n\n\nYou can include Open Street Map basemaps using the \nOpenlayers plugin\n but only openstreetmaps, google imagery causes a segmentation fault with Qtiles\n\n\nKnown Issues\n\n\n\n\nTransparency doesn't seem to work\n\n\nCan't export with google imagery",
            "title": "Creating mbtiles with Qtiles"
        },
        {
            "location": "/QGIS:-QTiles/#installation",
            "text": "Plugin Manager  Enable Experimental Plugins  Install Qtiles",
            "title": "Installation"
        },
        {
            "location": "/QGIS:-QTiles/#usage",
            "text": "Create your GIS project in QGIS as you want it displayed and then access the qtiles plugin from the plugin menu at the top.",
            "title": "Usage"
        },
        {
            "location": "/QGIS:-QTiles/#basemaps",
            "text": "You can include Open Street Map basemaps using the  Openlayers plugin  but only openstreetmaps, google imagery causes a segmentation fault with Qtiles",
            "title": "Basemaps"
        },
        {
            "location": "/QGIS:-QTiles/#known-issues",
            "text": "Transparency doesn't seem to work  Can't export with google imagery",
            "title": "Known Issues"
        },
        {
            "location": "/Vector-Tiles/",
            "text": "GIS data typically will either be either a vector or raster data type. Tiled map services historically were raster based but with the advent of openstreetmaps vector tiles are becoming much more common with the added benefit of being slimmer and loading faster. ESRI also has their proprietary vector tile packages (vtpk) but I'm going to focus on Open Source formats.\n\n\nMapbox created the \nmbtile\n format which can be both vector and raster and is ideal for map services and is also utilised on mobile applications.\n\n\nLet's look at the process of creating a custom mbtile basemap.\n\n\nBasemap:\n\n\nYou can download basemap packages from https://openmaptiles.com/downloads/\n\n\nThese are all well and dandy but if you want something custom you'll need to find a way to generate your own data as well.\n\n\nGIS Data:\n\n\nYou can use QGIS or Arcmap to create your GIS data, \n\n\nProjection: EPSG 3857 or 4326\n\n\nThere are a few different tools for generating mbtiles:\n\n\n\n\nMapbox Studio Classic\n\n\nTippecanoe\n\n\nQtiles experimental QGIS plugin\n\n\n\n\nMapbox and tippecanoe seem to require geojson files as a prerequisite so you'll need to convert your GIS data to that format before you convert them to mbtiles\n\n\nOnline GeoJSON converters:\n\n\n\n\ntogeojson\n\n\nOgre\n\n\n\n\nIn theory you can also merge layers together with tippecanoe\n\n\ntippecanoe -L layer1:layer1.geojson -L layer2:layer2.geojson -o yourtiles.mbtiles\n\n\n\n\nthe Qtiles plugin converts whatever data you have loaded into mbtiles.\n\n\nMerging mbtiles\n\n\nNow that you have a few mbtiles layers you can merge them with \nmbutil\n by following \nthis guide\n\n\nIt seems \nLandez\n may also be an option but it may be a mashup with a transparency\n\n\nOnce they are merged if they worked properly you should have a custom basemap with your own layers that can be loaded on your fancy mobile device.\n\n\nBut if you want my opinion GeoPackage is a better standard for offline caches of GIS data.",
            "title": "Vector Tiles"
        },
        {
            "location": "/Vector-Tiles/#basemap",
            "text": "You can download basemap packages from https://openmaptiles.com/downloads/  These are all well and dandy but if you want something custom you'll need to find a way to generate your own data as well.",
            "title": "Basemap:"
        },
        {
            "location": "/Vector-Tiles/#gis-data",
            "text": "You can use QGIS or Arcmap to create your GIS data,   Projection: EPSG 3857 or 4326  There are a few different tools for generating mbtiles:   Mapbox Studio Classic  Tippecanoe  Qtiles experimental QGIS plugin   Mapbox and tippecanoe seem to require geojson files as a prerequisite so you'll need to convert your GIS data to that format before you convert them to mbtiles  Online GeoJSON converters:   togeojson  Ogre   In theory you can also merge layers together with tippecanoe  tippecanoe -L layer1:layer1.geojson -L layer2:layer2.geojson -o yourtiles.mbtiles  the Qtiles plugin converts whatever data you have loaded into mbtiles.",
            "title": "GIS Data:"
        },
        {
            "location": "/Vector-Tiles/#merging-mbtiles",
            "text": "Now that you have a few mbtiles layers you can merge them with  mbutil  by following  this guide  It seems  Landez  may also be an option but it may be a mashup with a transparency  Once they are merged if they worked properly you should have a custom basemap with your own layers that can be loaded on your fancy mobile device.  But if you want my opinion GeoPackage is a better standard for offline caches of GIS data.",
            "title": "Merging mbtiles"
        },
        {
            "location": "/GDAL-and-OGR/",
            "text": "GDAL/OGR are libraries for converting GIS data among other things. Historically GDAL was used for raster formats and OGR for vector formats.\n\n\nInstallation\n\n\nTo install on Ubuntu add the repository:\n\n\nsudo add-apt-repository ppa:ubuntugis/ppa && sudo apt-get update\n\n\n\n\nInstall\n\n\nsudo apt-get install gdal-bin\n\n\n\n\nCheck if its installed with \nogrinfo\n and it will yield something like this:\n\n\nUsage: ogrinfo [--help-general] [-ro] [-q] [-where restricted_where|@filename]\n               [-spat xmin ymin xmax ymax] [-geomfield field] [-fid fid]\n               [-sql statement|@filename] [-dialect sql_dialect] [-al] [-so] [-fields={YES/NO}]\n               [-geom={YES/NO/SUMMARY}] [-formats] [[-oo NAME=VALUE] ...]\n               [-nomd] [-listmdd] [-mdd domain|`all`]*\n               [-nocount] [-noextent]\n               datasource_name [layer [layer ...]]\n\nFAILURE: No datasource specified.\n\n\n\n\nTest KMZ/KMLS https://storage.googleapis.com/google-code-archive-source/v2/code.google.com/kml-samples/source-archive.zip\n\n\nTest KMLS/KMZS:\n\n\nogrinfo time-stamp-point.kmz -al -so\n\n\n\n\nfor the kmz if you dont have libkml (not that this is useful or anything):\n\n\nogrinfo /vsizip/time-stamp-point.kmz -al -so --config ogr_skip libkml\n\n\n\n\nConvert KMZ to MBTILES\n\n\nKmz to GeoJSON\n\n\nogr2ogr -f GeoJSON yourgeojson.json yourkmz.kmz\n\n\n\n\nInstalling Tippecanoe\n\n\nDependencies:\n\n\nsudo apt-get install build-essential libsqlite3-dev zlib1g-dev\n\n\n\n\nInstall\n\n\ngit clone https://github.com/mapbox/tippecanoe.git\ncd tippecanoe\nmake\nsudo make install\n\n\n\n\nCreate Mbtiles:\nFor one layer\n\n\ntippecanoe yourgeojson.geojson -o yourtiles.mbtiles\n\n\n\n\nfor multiple layers\n\n\ntippecanoe -L layer1:layer1.geojson -L layer2:layer2.geojson -o yourtiles.mbtiles",
            "title": "GDAL and OGR"
        },
        {
            "location": "/GDAL-and-OGR/#installation",
            "text": "To install on Ubuntu add the repository:  sudo add-apt-repository ppa:ubuntugis/ppa && sudo apt-get update  Install  sudo apt-get install gdal-bin  Check if its installed with  ogrinfo  and it will yield something like this:  Usage: ogrinfo [--help-general] [-ro] [-q] [-where restricted_where|@filename]\n               [-spat xmin ymin xmax ymax] [-geomfield field] [-fid fid]\n               [-sql statement|@filename] [-dialect sql_dialect] [-al] [-so] [-fields={YES/NO}]\n               [-geom={YES/NO/SUMMARY}] [-formats] [[-oo NAME=VALUE] ...]\n               [-nomd] [-listmdd] [-mdd domain|`all`]*\n               [-nocount] [-noextent]\n               datasource_name [layer [layer ...]]\n\nFAILURE: No datasource specified.  Test KMZ/KMLS https://storage.googleapis.com/google-code-archive-source/v2/code.google.com/kml-samples/source-archive.zip  Test KMLS/KMZS:  ogrinfo time-stamp-point.kmz -al -so  for the kmz if you dont have libkml (not that this is useful or anything):  ogrinfo /vsizip/time-stamp-point.kmz -al -so --config ogr_skip libkml",
            "title": "Installation"
        },
        {
            "location": "/GDAL-and-OGR/#convert-kmz-to-mbtiles",
            "text": "",
            "title": "Convert KMZ to MBTILES"
        },
        {
            "location": "/GDAL-and-OGR/#kmz-to-geojson",
            "text": "ogr2ogr -f GeoJSON yourgeojson.json yourkmz.kmz",
            "title": "Kmz to GeoJSON"
        },
        {
            "location": "/GDAL-and-OGR/#installing-tippecanoe",
            "text": "Dependencies:  sudo apt-get install build-essential libsqlite3-dev zlib1g-dev  Install  git clone https://github.com/mapbox/tippecanoe.git\ncd tippecanoe\nmake\nsudo make install  Create Mbtiles:\nFor one layer  tippecanoe yourgeojson.geojson -o yourtiles.mbtiles  for multiple layers  tippecanoe -L layer1:layer1.geojson -L layer2:layer2.geojson -o yourtiles.mbtiles",
            "title": "Installing Tippecanoe"
        }
    ]
}